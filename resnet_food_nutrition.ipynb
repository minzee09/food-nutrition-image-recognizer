{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6nPXN7pCHkQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrQy_wkirKlr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eaoBTRk_HpiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "PG-aGCR9Fd-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# food101(음식 이미지) 데이터셋\n",
        "food101_dataset = tfds.load('food101', split='train', as_supervised=True)"
      ],
      "metadata": {
        "id": "OWKzVMJyredx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model pre-trained on ImageNet dataset\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "bi-YmtQKFkYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78703d8f-12b5-431c-f9b7-fb003d635afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 전처리 함수 정의\n",
        "def preprocess_image_with_nutrition(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "    #label 텐서에서 문자열(string) 텐서로 변환\n",
        "    label_str = tf.strings.as_string(label)\n",
        "\n",
        "    # DB를 참고하여 영양성분 정보 매핑\n",
        "    nutrition_mapping = {\n",
        "        'bibimbap': {'sugar': 18.3, 'carbs': 98.7, 'protein': 24.6, 'fat': 22},\n",
        "        'apple_pie': {'sugar': 9, 'carbs': 3, 'protein': 0, 'fat': 0},\n",
        "        'baby_back_ribs': {'sugar': 14.43, 'carbs': 10.43, 'protein': 84.72, 'fat': 55.61},\n",
        "        'beef_carpaccio': {'sugar': 7.93, 'carbs': 12.18, 'protein': 14.9, 'fat': 9.64}\n",
        "        # 모델 연결까지 완결된 뒤에 추가할 예정\n",
        "    }\n",
        "\n",
        "    # Flatten the dictionaries into lists of scalar values\n",
        "    nutrition_list = [list(values.values()) for values in nutrition_mapping.values()]\n",
        "\n",
        "    # 영양 성분 리스트 텐서로 변환\n",
        "    nutrition_tensor = tf.constant(nutrition_list, dtype=tf.float32)\n",
        "\n",
        "    # 영양 정보 레이블에 따라 추출\n",
        "    default_nutrition = {'sugar': 0, 'carbs': 0, 'protein': 0, 'fat': 0}\n",
        "    hashable_label_str = tf.strings.to_hash_bucket_fast(label_str, 100)\n",
        "    nutritional_info = tf.cond(tf.greater(tf.strings.length(label_str), 0),\n",
        "                               lambda: tf.gather(nutrition_tensor, hashable_label_str),\n",
        "                               lambda: tf.constant(list(default_nutrition.values()), dtype=tf.float32))\n",
        "\n",
        "    return image, nutritional_info"
      ],
      "metadata": {
        "id": "nzUCEIaaroJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 매핑\n",
        "food101_dataset = food101_dataset.map(preprocess_image_with_nutrition)"
      ],
      "metadata": {
        "id": "wUBlgsByrmrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치\n",
        "batch_size = 32\n",
        "food101_dataset = food101_dataset.shuffle(buffer_size=len(food101_dataset)).batch(batch_size)"
      ],
      "metadata": {
        "id": "F1wKeR_2wjhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의(Resnet은 X)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(4)\n",
        "])"
      ],
      "metadata": {
        "id": "ipkwI8ahwnIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iKPlDQowwpf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(food101_dataset, epochs=5)  # Adjust epochs as needed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "RKUns39VwrM-",
        "outputId": "d0b98b4f-85c7-41db-d0e3-9463910c9caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node cond/GatherV2_tfg_inlined_cond_0 defined at (most recent call last):\n<stack traces unavailable>\nindices = 90 is not in [0, 4)\n\t [[{{node cond/GatherV2_tfg_inlined_cond_0}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5093]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b649d173e5fd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood101_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust epochs as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node cond/GatherV2_tfg_inlined_cond_0 defined at (most recent call last):\n<stack traces unavailable>\nindices = 90 is not in [0, 4)\n\t [[{{node cond/GatherV2_tfg_inlined_cond_0}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5093]"
          ]
        }
      ]
    }
  ]
}